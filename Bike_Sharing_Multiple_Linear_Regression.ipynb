{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if filename.startswith('bike'):\n            print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-25T16:14:14.450698Z","iopub.execute_input":"2024-05-25T16:14:14.451562Z","iopub.status.idle":"2024-05-25T16:14:14.464931Z","shell.execute_reply.started":"2024-05-25T16:14:14.451528Z","shell.execute_reply":"2024-05-25T16:14:14.463923Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"/kaggle/input/av-ms-ds/bike-sharing-Readme.txt\n/kaggle/input/av-ms-ds/bike-sharing-day.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:14.492382Z","iopub.execute_input":"2024-05-25T16:14:14.493047Z","iopub.status.idle":"2024-05-25T16:14:14.496745Z","shell.execute_reply.started":"2024-05-25T16:14:14.493024Z","shell.execute_reply":"2024-05-25T16:14:14.495850Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:14.539407Z","iopub.execute_input":"2024-05-25T16:14:14.539672Z","iopub.status.idle":"2024-05-25T16:14:14.545860Z","shell.execute_reply.started":"2024-05-25T16:14:14.539650Z","shell.execute_reply":"2024-05-25T16:14:14.545000Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"bike_df = pd.DataFrame(pd.read_csv(\"/kaggle/input/av-ms-ds/bike-sharing-day.csv\"))\nbike_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:14.593523Z","iopub.execute_input":"2024-05-25T16:14:14.593786Z","iopub.status.idle":"2024-05-25T16:14:14.613787Z","shell.execute_reply.started":"2024-05-25T16:14:14.593764Z","shell.execute_reply":"2024-05-25T16:14:14.612926Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n0        1  01-01-2018       1   0     1        0        6           0   \n1        2  02-01-2018       1   0     1        0        0           0   \n2        3  03-01-2018       1   0     1        0        1           1   \n3        4  04-01-2018       1   0     1        0        2           1   \n4        5  05-01-2018       1   0     1        0        3           1   \n\n   weathersit       temp     atemp      hum  windspeed  casual  registered  \\\n0           2  14.110847  18.18125  80.5833  10.749882     331         654   \n1           2  14.902598  17.68695  69.6087  16.652113     131         670   \n2           1   8.050924   9.47025  43.7273  16.636703     120        1229   \n3           1   8.200000  10.60610  59.0435  10.739832     108        1454   \n4           1   9.305237  11.46350  43.6957  12.522300      82        1518   \n\n    cnt  \n0   985  \n1   801  \n2  1349  \n3  1562  \n4  1600  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instant</th>\n      <th>dteday</th>\n      <th>season</th>\n      <th>yr</th>\n      <th>mnth</th>\n      <th>holiday</th>\n      <th>weekday</th>\n      <th>workingday</th>\n      <th>weathersit</th>\n      <th>temp</th>\n      <th>atemp</th>\n      <th>hum</th>\n      <th>windspeed</th>\n      <th>casual</th>\n      <th>registered</th>\n      <th>cnt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>01-01-2018</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>14.110847</td>\n      <td>18.18125</td>\n      <td>80.5833</td>\n      <td>10.749882</td>\n      <td>331</td>\n      <td>654</td>\n      <td>985</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>02-01-2018</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>14.902598</td>\n      <td>17.68695</td>\n      <td>69.6087</td>\n      <td>16.652113</td>\n      <td>131</td>\n      <td>670</td>\n      <td>801</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>03-01-2018</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8.050924</td>\n      <td>9.47025</td>\n      <td>43.7273</td>\n      <td>16.636703</td>\n      <td>120</td>\n      <td>1229</td>\n      <td>1349</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>04-01-2018</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8.200000</td>\n      <td>10.60610</td>\n      <td>59.0435</td>\n      <td>10.739832</td>\n      <td>108</td>\n      <td>1454</td>\n      <td>1562</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>05-01-2018</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9.305237</td>\n      <td>11.46350</td>\n      <td>43.6957</td>\n      <td>12.522300</td>\n      <td>82</td>\n      <td>1518</td>\n      <td>1600</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"bike_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:14.635299Z","iopub.execute_input":"2024-05-25T16:14:14.635557Z","iopub.status.idle":"2024-05-25T16:14:14.640675Z","shell.execute_reply.started":"2024-05-25T16:14:14.635535Z","shell.execute_reply":"2024-05-25T16:14:14.639879Z"},"trusted":true},"execution_count":122,"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"(730, 16)"},"metadata":{}}]},{"cell_type":"code","source":"bike_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:14.675949Z","iopub.execute_input":"2024-05-25T16:14:14.676509Z","iopub.status.idle":"2024-05-25T16:14:14.685963Z","shell.execute_reply.started":"2024-05-25T16:14:14.676485Z","shell.execute_reply":"2024-05-25T16:14:14.685105Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 730 entries, 0 to 729\nData columns (total 16 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   instant     730 non-null    int64  \n 1   dteday      730 non-null    object \n 2   season      730 non-null    int64  \n 3   yr          730 non-null    int64  \n 4   mnth        730 non-null    int64  \n 5   holiday     730 non-null    int64  \n 6   weekday     730 non-null    int64  \n 7   workingday  730 non-null    int64  \n 8   weathersit  730 non-null    int64  \n 9   temp        730 non-null    float64\n 10  atemp       730 non-null    float64\n 11  hum         730 non-null    float64\n 12  windspeed   730 non-null    float64\n 13  casual      730 non-null    int64  \n 14  registered  730 non-null    int64  \n 15  cnt         730 non-null    int64  \ndtypes: float64(4), int64(11), object(1)\nmemory usage: 91.4+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"bike_df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:14.719800Z","iopub.execute_input":"2024-05-25T16:14:14.720082Z","iopub.status.idle":"2024-05-25T16:14:14.766428Z","shell.execute_reply.started":"2024-05-25T16:14:14.720047Z","shell.execute_reply":"2024-05-25T16:14:14.765519Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"          instant      season          yr        mnth     holiday     weekday  \\\ncount  730.000000  730.000000  730.000000  730.000000  730.000000  730.000000   \nmean   365.500000    2.498630    0.500000    6.526027    0.028767    2.997260   \nstd    210.877136    1.110184    0.500343    3.450215    0.167266    2.006161   \nmin      1.000000    1.000000    0.000000    1.000000    0.000000    0.000000   \n25%    183.250000    2.000000    0.000000    4.000000    0.000000    1.000000   \n50%    365.500000    3.000000    0.500000    7.000000    0.000000    3.000000   \n75%    547.750000    3.000000    1.000000   10.000000    0.000000    5.000000   \nmax    730.000000    4.000000    1.000000   12.000000    1.000000    6.000000   \n\n       workingday  weathersit        temp       atemp         hum   windspeed  \\\ncount  730.000000  730.000000  730.000000  730.000000  730.000000  730.000000   \nmean     0.683562    1.394521   20.319259   23.726322   62.765175   12.763620   \nstd      0.465405    0.544807    7.506729    8.150308   14.237589    5.195841   \nmin      0.000000    1.000000    2.424346    3.953480    0.000000    1.500244   \n25%      0.000000    1.000000   13.811885   16.889713   52.000000    9.041650   \n50%      1.000000    1.000000   20.465826   24.368225   62.625000   12.125325   \n75%      1.000000    2.000000   26.880615   30.445775   72.989575   15.625589   \nmax      1.000000    3.000000   35.328347   42.044800   97.250000   34.000021   \n\n            casual   registered          cnt  \ncount   730.000000   730.000000   730.000000  \nmean    849.249315  3658.757534  4508.006849  \nstd     686.479875  1559.758728  1936.011647  \nmin       2.000000    20.000000    22.000000  \n25%     316.250000  2502.250000  3169.750000  \n50%     717.000000  3664.500000  4548.500000  \n75%    1096.500000  4783.250000  5966.000000  \nmax    3410.000000  6946.000000  8714.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instant</th>\n      <th>season</th>\n      <th>yr</th>\n      <th>mnth</th>\n      <th>holiday</th>\n      <th>weekday</th>\n      <th>workingday</th>\n      <th>weathersit</th>\n      <th>temp</th>\n      <th>atemp</th>\n      <th>hum</th>\n      <th>windspeed</th>\n      <th>casual</th>\n      <th>registered</th>\n      <th>cnt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n      <td>730.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>365.500000</td>\n      <td>2.498630</td>\n      <td>0.500000</td>\n      <td>6.526027</td>\n      <td>0.028767</td>\n      <td>2.997260</td>\n      <td>0.683562</td>\n      <td>1.394521</td>\n      <td>20.319259</td>\n      <td>23.726322</td>\n      <td>62.765175</td>\n      <td>12.763620</td>\n      <td>849.249315</td>\n      <td>3658.757534</td>\n      <td>4508.006849</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>210.877136</td>\n      <td>1.110184</td>\n      <td>0.500343</td>\n      <td>3.450215</td>\n      <td>0.167266</td>\n      <td>2.006161</td>\n      <td>0.465405</td>\n      <td>0.544807</td>\n      <td>7.506729</td>\n      <td>8.150308</td>\n      <td>14.237589</td>\n      <td>5.195841</td>\n      <td>686.479875</td>\n      <td>1559.758728</td>\n      <td>1936.011647</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.424346</td>\n      <td>3.953480</td>\n      <td>0.000000</td>\n      <td>1.500244</td>\n      <td>2.000000</td>\n      <td>20.000000</td>\n      <td>22.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>183.250000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>13.811885</td>\n      <td>16.889713</td>\n      <td>52.000000</td>\n      <td>9.041650</td>\n      <td>316.250000</td>\n      <td>2502.250000</td>\n      <td>3169.750000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>365.500000</td>\n      <td>3.000000</td>\n      <td>0.500000</td>\n      <td>7.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>20.465826</td>\n      <td>24.368225</td>\n      <td>62.625000</td>\n      <td>12.125325</td>\n      <td>717.000000</td>\n      <td>3664.500000</td>\n      <td>4548.500000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>547.750000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>10.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>26.880615</td>\n      <td>30.445775</td>\n      <td>72.989575</td>\n      <td>15.625589</td>\n      <td>1096.500000</td>\n      <td>4783.250000</td>\n      <td>5966.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>730.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>12.000000</td>\n      <td>1.000000</td>\n      <td>6.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>35.328347</td>\n      <td>42.044800</td>\n      <td>97.250000</td>\n      <td>34.000021</td>\n      <td>3410.000000</td>\n      <td>6946.000000</td>\n      <td>8714.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Highlevel observations from the dataframe","metadata":{}},{"cell_type":"markdown","source":"* Dataset has 16 columns and 730 rows.\n\n* Except one column (dteday: object), all other are either float(float64) or integer(int64) type.\n\n* dteday column is object type, but it has to be of date data type.\n\n* At the highlevel, there seems to be some fields that are categorical in nature, but in integer/float type.\n \n* We will analyse and finalize whether to convert them to categorical(discrete) or treat as integer(continuous)","metadata":{}},{"cell_type":"markdown","source":"## Inspect Null or Missing values","metadata":{}},{"cell_type":"code","source":"# percentage of missing values in each column\nround(100*(bike_df.isnull().sum()/len(bike_df)), 2).sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:14.805302Z","iopub.execute_input":"2024-05-25T16:14:14.805757Z","iopub.status.idle":"2024-05-25T16:14:14.814982Z","shell.execute_reply.started":"2024-05-25T16:14:14.805732Z","shell.execute_reply":"2024-05-25T16:14:14.814077Z"},"trusted":true},"execution_count":125,"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"instant       0.0\ndteday        0.0\nseason        0.0\nyr            0.0\nmnth          0.0\nholiday       0.0\nweekday       0.0\nworkingday    0.0\nweathersit    0.0\ntemp          0.0\natemp         0.0\nhum           0.0\nwindspeed     0.0\ncasual        0.0\nregistered    0.0\ncnt           0.0\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"round((bike_df.isnull().sum(axis=1)/len(bike_df))*100,2).sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:14.876329Z","iopub.execute_input":"2024-05-25T16:14:14.876578Z","iopub.status.idle":"2024-05-25T16:14:14.886736Z","shell.execute_reply.started":"2024-05-25T16:14:14.876556Z","shell.execute_reply":"2024-05-25T16:14:14.885791Z"},"trusted":true},"execution_count":126,"outputs":[{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"729    0.0\n0      0.0\n1      0.0\n2      0.0\n3      0.0\n      ... \n29     0.0\n30     0.0\n31     0.0\n32     0.0\n33     0.0\nLength: 730, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"There are no missing / Null values either in columns or rows","metadata":{}},{"cell_type":"markdown","source":"### Checking for duplicates and dropping the entire duplicate row if any","metadata":{}},{"cell_type":"code","source":"bike_df_copy = bike_df.copy()\n\n\nbike_df_copy.drop_duplicates(subset=None, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:14.944964Z","iopub.execute_input":"2024-05-25T16:14:14.945240Z","iopub.status.idle":"2024-05-25T16:14:14.953459Z","shell.execute_reply.started":"2024-05-25T16:14:14.945218Z","shell.execute_reply":"2024-05-25T16:14:14.952565Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"bike_df_copy.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:14.987985Z","iopub.execute_input":"2024-05-25T16:14:14.988280Z","iopub.status.idle":"2024-05-25T16:14:14.993497Z","shell.execute_reply.started":"2024-05-25T16:14:14.988257Z","shell.execute_reply":"2024-05-25T16:14:14.992654Z"},"trusted":true},"execution_count":128,"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"(730, 16)"},"metadata":{}}]},{"cell_type":"code","source":"bike_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:15.026314Z","iopub.execute_input":"2024-05-25T16:14:15.026588Z","iopub.status.idle":"2024-05-25T16:14:15.032013Z","shell.execute_reply.started":"2024-05-25T16:14:15.026565Z","shell.execute_reply":"2024-05-25T16:14:15.031102Z"},"trusted":true},"execution_count":129,"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"(730, 16)"},"metadata":{}}]},{"cell_type":"markdown","source":"There is no reduction in rows in copied df since there is no duplicates found.\n\nSo we can conclude that there were zero duplicate values in the bike dataset.","metadata":{}},{"cell_type":"markdown","source":"Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"Let us check for `value_counts()` for entire dataframe to identify any Unknown/Junk values present in the dataset.","metadata":{}},{"cell_type":"code","source":"bike_temp=bike_df.iloc[:,1:16]","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:15.066796Z","iopub.execute_input":"2024-05-25T16:14:15.067257Z","iopub.status.idle":"2024-05-25T16:14:15.071543Z","shell.execute_reply.started":"2024-05-25T16:14:15.067226Z","shell.execute_reply":"2024-05-25T16:14:15.070488Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"bike_temp.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:15.107336Z","iopub.execute_input":"2024-05-25T16:14:15.107594Z","iopub.status.idle":"2024-05-25T16:14:15.122355Z","shell.execute_reply.started":"2024-05-25T16:14:15.107572Z","shell.execute_reply":"2024-05-25T16:14:15.121463Z"},"trusted":true},"execution_count":131,"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"       dteday  season  yr  mnth  holiday  weekday  workingday  weathersit  \\\n0  01-01-2018       1   0     1        0        6           0           2   \n1  02-01-2018       1   0     1        0        0           0           2   \n2  03-01-2018       1   0     1        0        1           1           1   \n3  04-01-2018       1   0     1        0        2           1           1   \n4  05-01-2018       1   0     1        0        3           1           1   \n\n        temp     atemp      hum  windspeed  casual  registered   cnt  \n0  14.110847  18.18125  80.5833  10.749882     331         654   985  \n1  14.902598  17.68695  69.6087  16.652113     131         670   801  \n2   8.050924   9.47025  43.7273  16.636703     120        1229  1349  \n3   8.200000  10.60610  59.0435  10.739832     108        1454  1562  \n4   9.305237  11.46350  43.6957  12.522300      82        1518  1600  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dteday</th>\n      <th>season</th>\n      <th>yr</th>\n      <th>mnth</th>\n      <th>holiday</th>\n      <th>weekday</th>\n      <th>workingday</th>\n      <th>weathersit</th>\n      <th>temp</th>\n      <th>atemp</th>\n      <th>hum</th>\n      <th>windspeed</th>\n      <th>casual</th>\n      <th>registered</th>\n      <th>cnt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01-01-2018</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>14.110847</td>\n      <td>18.18125</td>\n      <td>80.5833</td>\n      <td>10.749882</td>\n      <td>331</td>\n      <td>654</td>\n      <td>985</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>02-01-2018</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>14.902598</td>\n      <td>17.68695</td>\n      <td>69.6087</td>\n      <td>16.652113</td>\n      <td>131</td>\n      <td>670</td>\n      <td>801</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>03-01-2018</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8.050924</td>\n      <td>9.47025</td>\n      <td>43.7273</td>\n      <td>16.636703</td>\n      <td>120</td>\n      <td>1229</td>\n      <td>1349</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>04-01-2018</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8.200000</td>\n      <td>10.60610</td>\n      <td>59.0435</td>\n      <td>10.739832</td>\n      <td>108</td>\n      <td>1454</td>\n      <td>1562</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>05-01-2018</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9.305237</td>\n      <td>11.46350</td>\n      <td>43.6957</td>\n      <td>12.522300</td>\n      <td>82</td>\n      <td>1518</td>\n      <td>1600</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# util function to extract value counts for all the columns in a df\ndef extract_value_counts(df):\n    for col in df:\n        print(\"column name: \", col)\n        print('+'*50,'\\n\\n\\n',df[col].value_counts(ascending=False), '\\n\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:15.145886Z","iopub.execute_input":"2024-05-25T16:14:15.146174Z","iopub.status.idle":"2024-05-25T16:14:15.150619Z","shell.execute_reply.started":"2024-05-25T16:14:15.146151Z","shell.execute_reply":"2024-05-25T16:14:15.149777Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"extract_value_counts(bike_df)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:15.181716Z","iopub.execute_input":"2024-05-25T16:14:15.181965Z","iopub.status.idle":"2024-05-25T16:14:15.202965Z","shell.execute_reply.started":"2024-05-25T16:14:15.181944Z","shell.execute_reply":"2024-05-25T16:14:15.202092Z"},"trusted":true},"execution_count":133,"outputs":[{"name":"stdout","text":"column name:  instant\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n instant\n730    1\n1      1\n2      1\n3      1\n4      1\n      ..\n30     1\n31     1\n32     1\n33     1\n34     1\nName: count, Length: 730, dtype: int64 \n\n\n\ncolumn name:  dteday\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n dteday\n31-12-2019    1\n01-01-2018    1\n02-01-2018    1\n03-01-2018    1\n04-01-2018    1\n             ..\n30-01-2018    1\n31-01-2018    1\n01-02-2018    1\n02-02-2018    1\n03-02-2018    1\nName: count, Length: 730, dtype: int64 \n\n\n\ncolumn name:  season\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n season\n3    188\n2    184\n1    180\n4    178\nName: count, dtype: int64 \n\n\n\ncolumn name:  yr\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n yr\n0    365\n1    365\nName: count, dtype: int64 \n\n\n\ncolumn name:  mnth\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n mnth\n1     62\n3     62\n7     62\n5     62\n12    62\n10    62\n8     62\n4     60\n9     60\n6     60\n11    60\n2     56\nName: count, dtype: int64 \n\n\n\ncolumn name:  holiday\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n holiday\n0    709\n1     21\nName: count, dtype: int64 \n\n\n\ncolumn name:  weekday\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n weekday\n6    105\n0    105\n1    105\n2    104\n4    104\n5    104\n3    103\nName: count, dtype: int64 \n\n\n\ncolumn name:  workingday\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n workingday\n1    499\n0    231\nName: count, dtype: int64 \n\n\n\ncolumn name:  weathersit\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n weathersit\n1    463\n2    246\n3     21\nName: count, dtype: int64 \n\n\n\ncolumn name:  temp\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n temp\n10.899153    5\n26.035000    5\n17.937500    4\n27.880000    4\n28.563347    4\n            ..\n31.433347    1\n30.442500    1\n29.110000    1\n32.116653    1\n28.989419    1\nName: count, Length: 498, dtype: int64 \n\n\n\ncolumn name:  atemp\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n atemp\n32.73440    4\n31.85040    3\n18.78105    3\n12.15290    2\n35.16460    2\n           ..\n30.46145    1\n30.10650    1\n31.34500    1\n27.68355    1\n31.66065    1\nName: count, Length: 689, dtype: int64 \n\n\n\ncolumn name:  hum\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n hum\n61.3333    4\n57.0000    3\n69.7083    3\n59.0000    3\n59.0417    3\n          ..\n91.7083    1\n93.9565    1\n89.7917    1\n71.3750    1\n63.9167    1\nName: count, Length: 594, dtype: int64 \n\n\n\ncolumn name:  windspeed\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n windspeed\n9.166739     3\n10.042161    3\n11.166689    3\n7.125450     3\n7.416900     3\n            ..\n12.999139    1\n10.374682    1\n10.749882    1\n16.652113    1\n11.625639    1\nName: count, Length: 649, dtype: int64 \n\n\n\ncolumn name:  casual\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n casual\n120     4\n968     4\n163     3\n775     3\n653     3\n       ..\n1750    1\n1633    1\n690     1\n701     1\n1236    1\nName: count, Length: 605, dtype: int64 \n\n\n\ncolumn name:  registered\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n registered\n1707    3\n6248    3\n4841    3\n1506    2\n2419    2\n       ..\n3231    1\n4018    1\n3077    1\n2921    1\n1878    1\nName: count, Length: 678, dtype: int64 \n\n\n\ncolumn name:  cnt\n++++++++++++++++++++++++++++++++++++++++++++++++++ \n\n\n cnt\n2077    2\n1977    2\n2425    2\n4073    2\n5312    2\n       ..\n5046    1\n4713    1\n4763    1\n4785    1\n4484    1\nName: count, Length: 695, dtype: int64 \n\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"After observing the above data we could conclude there is no null or unknown values in the dataframe.\n","metadata":{}},{"cell_type":"markdown","source":"### Removing redundant & unwanted columns\n\nBased on a high-level review of the data and the data dictionary, the following variables can be removed from further analysis:\n\n| Variable | Reason for Removal |\n|---|---|\n| **`instant`** | 📅 **Index Value**: It's merely an index and does not provide useful information for analysis. |\n| **`dteday`** | 📆 **Date Column**: We already have separate columns for 'year' and 'month', so this column is redundant. |\n| **`casual`** & **`registered`** | 🚴‍♂️ **Customer Counts**: These columns contain the count of bikes booked by different customer categories. Our objective is to find the total count of bikes, not by specific category. Additionally, we have created a new variable to represent the ratio of these customer types. |\n\nWe will save the new dataframe as `bike_refined_df` to preserve the original dataset for any future analysis or validation.\n\n","metadata":{}},{"cell_type":"code","source":" #Lets delete all the columns which value is unique in nature by verifiying as shown below.\n\nunique_columns = [col for col in bike_df.columns if bike_df[col].nunique() == len(bike_df)]\nunique_columns","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:15.207317Z","iopub.execute_input":"2024-05-25T16:14:15.207589Z","iopub.status.idle":"2024-05-25T16:14:15.215980Z","shell.execute_reply.started":"2024-05-25T16:14:15.207565Z","shell.execute_reply":"2024-05-25T16:14:15.215121Z"},"trusted":true},"execution_count":134,"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"['instant', 'dteday']"},"metadata":{}}]},{"cell_type":"code","source":"bike_df.columns","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:15.233328Z","iopub.execute_input":"2024-05-25T16:14:15.233663Z","iopub.status.idle":"2024-05-25T16:14:15.239538Z","shell.execute_reply.started":"2024-05-25T16:14:15.233630Z","shell.execute_reply":"2024-05-25T16:14:15.238675Z"},"trusted":true},"execution_count":135,"outputs":[{"execution_count":135,"output_type":"execute_result","data":{"text/plain":"Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'holiday', 'weekday',\n       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n       'casual', 'registered', 'cnt'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Dropping casual and Registed as  they sumed to Cnt.","metadata":{}},{"cell_type":"code","source":"bike_df.drop(['casual','registered'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:14:15.252766Z","iopub.execute_input":"2024-05-25T16:14:15.253026Z","iopub.status.idle":"2024-05-25T16:14:15.257971Z","shell.execute_reply.started":"2024-05-25T16:14:15.253004Z","shell.execute_reply":"2024-05-25T16:14:15.257045Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"bike_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_refined_df = bike_df[['season', 'yr', 'mnth', 'holiday', 'weekday',\n       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n       'cnt']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_refined_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Perform the EDA on (bike_refined_df) Dataset.","metadata":{}},{"cell_type":"code","source":"# function to create barplot related to categorical columns\n\ndef plot_bar_graphs(df,column):\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    sns.barplot(x=column, y='cnt', data=df)\n    plt.title(f'Bar Plot of {column} vs cnt')\n    \n    plt.subplot(1, 2, 2)\n    sns.barplot(x=column, y='cnt', data=df, hue='yr', palette='Set1')\n    plt.title(f'Bar Plot of {column} vs cnt (2018 vs 2019)')\n    plt.legend(title='yr', labels=['2018', '2019'])\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check if any outliers present is numeric featires.\n# raw box plots for indepent variables with continuous values\ncols = ['temp', 'atemp', 'hum', 'windspeed']\nplt.figure(figsize=(18,4))\n\nk = 1\nfor col in cols:\n    plt.subplot(1,4,k)\n    sns.boxplot(y=col, data=bike_refined_df)\n    k+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Line graph will that show the count vs month for year 2018 and 2019.\nsns.lineplot(x = \"mnth\", y = \"cnt\", data=bike_refined_df,hue = \"yr\")\nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inferences:\n# 1. From Line Graph we can see that target Variable cnt has increased from 2018 to 2019.\n# 2. Demand for bike is high between may to oct for year 2018 and 2019.\n# 3. From Boxchart we can also see that there is no outliers present.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets plot pairplots to have better to see if cnt is linearly  depend upon is independet variables. \nnumerical_variabels=['cnt', 'temp', 'atemp', 'hum','windspeed']\nsns.pairplot(data=bike_refined_df,vars=numerical_variabels, kind=\"reg\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inferences:\n1. We can see that we have linealy dependecy between temp, atemp and count.\n2. we can also see that temp and atemp is highly correlated.","metadata":{"execution":{"iopub.status.busy":"2024-05-25T15:01:27.635485Z","iopub.execute_input":"2024-05-25T15:01:27.635781Z","iopub.status.idle":"2024-05-25T15:01:27.639652Z","shell.execute_reply.started":"2024-05-25T15:01:27.635756Z","shell.execute_reply":"2024-05-25T15:01:27.638698Z"}}},{"cell_type":"markdown","source":"#  Barcharts for categorical variables to see demands","metadata":{}},{"cell_type":"code","source":"plot_bar_graphs(bike_refined_df,'season')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inferences:\n1. Fall  seasons is having high number bike rental.\n2. Bike rental in 2019 has increaded for every seasion compared to 2018.","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:58:02.408687Z","iopub.execute_input":"2024-05-25T14:58:02.409016Z","iopub.status.idle":"2024-05-25T14:58:02.738835Z","shell.execute_reply.started":"2024-05-25T14:58:02.408992Z","shell.execute_reply":"2024-05-25T14:58:02.737440Z"}}},{"cell_type":"code","source":"plot_bar_graphs(bike_refined_df,'mnth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inferences:\n1. May to oct is having number of bike registration.\n2. Bike registration in 2019 has increaded for every month compared to 2018.","metadata":{}},{"cell_type":"code","source":"plot_bar_graphs(bike_refined_df,'weathersit')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inferences:\n1. People prefer bike rental when weather situations is good. \n2. Bike registration in 2019 has increaded  for every weather situtation 2018.","metadata":{}},{"cell_type":"code","source":"plot_bar_graphs(bike_refined_df,'weekday')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inferences:\n1. People don't prefer bike rental on weekends. ","metadata":{}},{"cell_type":"code","source":"plot_bar_graphs(bike_refined_df,'holiday')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inferences:\n1. People dont prefer renting bike holiday.","metadata":{}},{"cell_type":"code","source":"plot_bar_graphs(bike_refined_df,'workingday')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inferences:\n1. People prefer bike rental on working days.","metadata":{}},{"cell_type":"markdown","source":"Lets draw heatMap to indentify is there any correlation.","metadata":{"execution":{"iopub.status.busy":"2024-05-25T15:46:05.473998Z","iopub.execute_input":"2024-05-25T15:46:05.474325Z","iopub.status.idle":"2024-05-25T15:46:05.482938Z","shell.execute_reply.started":"2024-05-25T15:46:05.474299Z","shell.execute_reply":"2024-05-25T15:46:05.479305Z"}}},{"cell_type":"code","source":"# Lets plot the corrlation matrix(heatmap)\nplt.figure(figsize=(25,10))\nsns.heatmap(bike_refined_df.corr(), cmap='BuGn', annot = True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inferences from heatmap: \n1. Since Count is sum of casual and registed. That we can infer from  heatmap as casual and registered are highly correleted with cnt. \n2. holiday, hum, and windspeed is negatively correlated. \n3. Indepedent variable temp and atemp is highly correlated(0.99). This show that there is high possiblity that one may have derived from another,One of the them can be dropped. Will use VIP and p values to drop this.","metadata":{}},{"cell_type":"code","source":"bike_refined_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dummy Variables","metadata":{}},{"cell_type":"markdown","source":"We will create Dummy variables for these 4 categorical variables 'mnth', 'weekday', 'season' & 'weathersit'.\n\nCreating dummy variables for categorical data is crucial in machine learning since most algorithms require numerical input. Categorical data in columns like 'mnth', 'weekday', 'season', and 'weathersit' need to be transformed into a numerical format to avoid ordinal assumptions that could mislead the model. Dummy variables, which create binary columns for each category, ensure that no false ordinal relationship is inferred.","metadata":{}},{"cell_type":"markdown","source":"We will have to convert them into 'category' data types, before creating dummy variables.\n\nBefore generating these dummy variables, converting the categorical columns to the 'category' data type offers significant benefits. This conversion reduces memory usage and speeds up computations compared to keeping the data in an 'object' (string) format or numerical types(assumed categorical types). Moreover, using the 'category' data type ensures that the data is consistently treated as categorical, maintaining data integrity throughout the preprocessing steps.","metadata":{}},{"cell_type":"code","source":"bike_refined_df['season']=bike_refined_df['season'].astype('category')\nbike_refined_df['weathersit']=bike_refined_df['weathersit'].astype('category')\nbike_refined_df['mnth']=bike_refined_df['mnth'].astype('category')\nbike_refined_df['weekday']=bike_refined_df['weekday'].astype('category')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_refined_df['season'].replace({1:\"spring\", 2:\"summer\", 3:\"fall\", 4:\"winter\"},inplace = True)\nbike_refined_df['weathersit'].replace({1:'good',2:'moderate',3:'bad',4:'severe'},inplace = True)\n\nbike_refined_df['mnth'].replace({1: 'jan',2: 'feb',3: 'mar',4: 'apr',5: 'may',6: 'jun',\n                  7: 'jul',8: 'aug',9: 'sept',10: 'oct',11: 'nov',12: 'dec'},inplace = True)\n\nbike_refined_df['weekday'].replace({0: 'sun',1: 'mon',2: 'tue',3: 'wed',4: 'thu',5: 'fri',6: 'sat'},inplace = True)\nbike_refined_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_refined_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nThe code provided performs the following three tasks:\n\n1. **Create Dummy Variables**: Converts categorical variables into dummy/indicator variables.\n2. **Drop Original Variable**: Removes the original categorical variable after converting it to dummy variables.\n3. **Drop First Dummy Variable**: Avoids the dummy variable trap by dropping the first dummy variable for each set of dummies created.\n\n### 🌟 Explanation\n\nHere's a step-by-step explanation with a focus on each task:\n\n#### 1️⃣ Create Dummy Variables\n\n**Creating dummy variables** means converting categorical variables into a series of binary (0 or 1) columns. Each unique category in the original variable becomes a new column.\n\n\n#### 2️⃣ Drop Original Variable\n\nAfter creating dummy variables, the original categorical variable is redundant and can be dropped. This is implicitly handled by `pd.get_dummies()` when creating dummies directly from the DataFrame.\n\n\n#### 3️⃣ Drop First Dummy Variable\n\nTo avoid multicollinearity (dummy variable trap), we drop the first dummy variable of each set. This ensures that the dummy variables are not linearly dependent.\n\nBy following these steps, the original categorical variables are transformed into a format suitable for machine learning models, avoiding issues like multicollinearity.","metadata":{}},{"cell_type":"code","source":"# This code does 3 things:\n# 1) Create Dummy variable\n# 2) Drop original variable for which the dummy was created\n# 3) Drop first dummy variable for each set of dummies created.\n\nbike_refined_df = pd.get_dummies(bike_refined_df, drop_first=True)\nbike_refined_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SPLITTING THE DATA\n\nSplitting the data to Train and Test: - We will now split the data into TRAIN and TEST \n\nWe will use train_test_split method from sklearn package for this using the ratio (70:30)","metadata":{}},{"cell_type":"code","source":"# Check the shape before spliting\n\nbike_refined_df.shape\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing train_test_split library from sklearn model selection package\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# specified 'random_state' so that the train and test data set always have the same rows, respectively\n\nnp.random.seed(0)\ndf_train, df_test = train_test_split(bike_refined_df, train_size = 0.70, test_size = 0.30, random_state = 777)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Perform the EDA on Training (df_train) Dataset","metadata":{}},{"cell_type":"markdown","source":"Visualising Numeric Variables using pairplot of all the numeric variables.","metadata":{}},{"cell_type":"code","source":"bike_num=df_train[[ 'temp', 'atemp', 'hum', 'windspeed','cnt']]\n\nsns.pairplot(bike_num, diag_kind='kde')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation\n\nThe above PairPlot tells us that there is likely a Linear relationship between 'temp','atemp' and 'cnt'","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:28:57.611750Z","iopub.execute_input":"2024-05-25T12:28:57.612089Z","iopub.status.idle":"2024-05-25T12:28:57.619980Z","shell.execute_reply.started":"2024-05-25T12:28:57.612060Z","shell.execute_reply":"2024-05-25T12:28:57.617008Z"}}},{"cell_type":"markdown","source":"## Visualising Catagorical Variables\n\nBuilding boxplot of all categorical variables (before creating dummies) againt the target variable 'cnt' to see how each of the predictor variable stackup against the target variable.\n\n","metadata":{}},{"cell_type":"code","source":"# Build boxplot of all categorical variables (before creating dummies) againt the target variable 'cnt' using bike_df\n# to see how each of the predictor variable stackup against the target variable.\n\nplt.figure(figsize=(25, 10))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'season', y = 'cnt', data = bike_df)\nplt.subplot(2,3,2)\nsns.boxplot(x = 'mnth', y = 'cnt', data = bike_df)\nplt.subplot(2,3,3)\nsns.boxplot(x = 'weathersit', y = 'cnt', data = bike_df)\nplt.subplot(2,3,4)\nsns.boxplot(x = 'holiday', y = 'cnt', data = bike_df)\nplt.subplot(2,3,5)\nsns.boxplot(x = 'weekday', y = 'cnt', data = bike_df)\nplt.subplot(2,3,6)\nsns.boxplot(x = 'workingday', y = 'cnt', data = bike_df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference Summary 🚲\n\nWe analyzed 6 categorical variables in the dataset using a Box plot to study their effect on the dependent variable, `cnt`. Here are the key insights derived:\n\n#### 📅 Season\n- **Insight:** Season 3 accounts for approximately 32% of bike bookings with a median of over 5000 bookings over two years.\n- **Comparison:** Season 2 and Season 4 follow with 27% and 25% of total bookings, respectively.\n- **Conclusion:** Season is a significant predictor for bike bookings.\n\n#### 📆 Month\n- **Insight:** About 10% of bike bookings occur during months 5, 6, 7, 8, and 9, with a median of over 4000 bookings per month.\n- **Conclusion:** Month shows a noticeable trend in bookings and can be a valuable predictor.\n\n#### 🌤 Weather Situation\n- **Insight:** Weather situation 1 (weathersit1) corresponds to nearly 67% of bike bookings with a median close to 5000 bookings over two years.\n- **Comparison:** Weather situation 2 (weathersit2) follows with 30% of total bookings.\n- **Conclusion:** Weather situation is a strong predictor of bike bookings.\n\n#### 📅 Holiday\n- **Insight:** Around 97.6% of bike bookings occur on non-holidays, indicating a clear bias.\n- **Conclusion:** Holiday status is not a reliable predictor for bike bookings.\n\n#### 📅 Weekday\n- **Insight:** Bookings are relatively uniform across weekdays, ranging between 13.5% to 14.8% with medians between 4000 to 5000 bookings.\n- **Conclusion:** The weekday variable may have a marginal influence, and the model should decide its inclusion.\n\n#### 🏢 Working Day\n- **Insight:** Approximately 69% of bike bookings occur on working days, with a median close to 5000 bookings over two years.\n- **Conclusion:** Working day is a significant predictor for bike bookings.\n\n### Comparison Table 🛠️\n\n| Variable    | % of Total Bookings | Median Bookings | Predictive Strength    |\n|-------------|---------------------|-----------------|------------------------|\n| **Season**  | 32% (Season 3)      | >5000           | High                   |\n| **Month**   | 10% (May-Sep)       | >4000           | Moderate               |\n| **Weather** | 67% (weathersit1)   | ~5000           | High                   |\n| **Holiday** | 97.6% (Non-holidays)| -               | Low                    |\n| **Weekday** | 13.5%-14.8%         | 4000-5000       | Uncertain              |\n| **Workday** | 69% (Workdays)      | ~5000           | High                   |\n\n### Conclusion 📝\n\nThe analysis indicates that **Season**, **Month**, **Weather Situation**, and **Working Day** are strong predictors of bike bookings. **Holiday** is not a reliable predictor, and the influence of **Weekday** is uncertain, best left for the model to decide.\n\n\nThis approach ensures a clear understanding of each variable's impact and aids in the decision-making process for predictive modeling.","metadata":{}},{"cell_type":"markdown","source":"## Correlation Matrix\n\nLet's use the correlation coefficients to see which variables are highly correlated. \n\nNote: here we are considering only those variables  that were chosen for analysis from bike_refined_df","metadata":{}},{"cell_type":"code","source":"# Let's check the correlation coefficients to see which variables are highly correlated. Note:\n# here we are considering only those variables  that were chosen for analysis from bike_refined_df\n\nplt.figure(figsize = (25,20))\nsns.heatmap(bike_refined_df.corr(), annot = True, cmap=\"RdBu\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations\n\n🔍 **Analyzing Collinearity by Understand a Heatmap:**\n- The heatmap provides a clear visualization of multicollinear variables and highlights those with high collinearity with the target variable. 📊\n\n🔄 **Using the Heatmap During Model Building:**\n- We will frequently reference this heatmap while constructing our linear model. 🏗️\n- By cross-checking correlated values with the heatmap, along with evaluating **Variance Inflation Factor (VIF)** and **p-values**, we can accurately determine which variables to include or exclude from our model. ✅❌\n\n### Process Overview\n\nLet's illustrate the process with a step-by-step approach:\n\n1. **Visualizing Collinearity:**\n    - Use a heatmap to display the correlation matrix of all variables.\n    - Identify variables that are highly correlated with each other and with the target variable.\n\n2. **Building the Linear Model:**\n    - Refer to the heatmap to validate correlated values.\n    - Calculate the VIF to assess the multicollinearity of each variable.\n    - Evaluate p-values to check the significance of each variable.\n\n3. **Variable Selection:**\n    - Use the combined insights from the heatmap, VIF, and p-values.\n    - Select or eliminate variables to refine the model.\n\n\n### Key Points\n\n| Aspect                 | Description                                            |\n|------------------------|--------------------------------------------------------|\n| **Heatmap**            | Visualizes multicollinearity between variables.        |\n| **VIF**                | Measures the multicollinearity of each variable.       |\n| **p-value**            | Determines the significance of each variable.          |\n| **Variable Selection** | Combines heatmap, VIF, and p-values for optimal choice.|\n\n\nUsing this structured approach ensures a robust and interpretable linear model. 🌟","metadata":{"execution":{"iopub.status.busy":"2024-05-25T11:45:34.334564Z","iopub.execute_input":"2024-05-25T11:45:34.334962Z","iopub.status.idle":"2024-05-25T11:45:34.348969Z","shell.execute_reply.started":"2024-05-25T11:45:34.334934Z","shell.execute_reply":"2024-05-25T11:45:34.347235Z"}}},{"cell_type":"markdown","source":"Bivariate analysis\n\nBarcharts for categorical variables to see demands","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SCALING THE FEATURES\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"scaler: This is an instance of a scaler object, likely from a library such as scikit-learn (sklearn.preprocessing.MinMaxScaler, for example). Scaling is a common preprocessing step in machine learning workflows, where you normalize the features to a similar scale to improve the performance of models, especially those sensitive to the scale of input features.","metadata":{}},{"cell_type":"code","source":"# Checking the columns before scaling\ndf_train.columns\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the values before scaling\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Apply scaler() to all the numeric variables","metadata":{}},{"cell_type":"code","source":"\n\n\n# the names of the numeric variables/columns that you want to scale\nnum_vars = ['temp', 'atemp', 'hum', 'windspeed','cnt']\n\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LINEAR MODEL BUILDING","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:36:15.014354Z","iopub.execute_input":"2024-05-25T12:36:15.014679Z","iopub.status.idle":"2024-05-25T12:36:15.027077Z","shell.execute_reply.started":"2024-05-25T12:36:15.014638Z","shell.execute_reply":"2024-05-25T12:36:15.024635Z"}}},{"cell_type":"markdown","source":"Dividing into X and Y sets for the model building","metadata":{}},{"cell_type":"code","source":"y_train = df_train.pop('cnt')\nX_train = df_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RFE\nRecursive feature elimination: We will be using the LinearRegression function from SciKit Learn for its compatibility with RFE (which is a utility from sklearn)","metadata":{}},{"cell_type":"code","source":"# Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Running RFE with the output number of the variable equal to 15\nLR = LinearRegression()\nestimator = LR.fit(X_train, y_train)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe = RFE(estimator, n_features_to_select=15)   # running RFE\nrfe = rfe.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### listing recommended columns","metadata":{}},{"cell_type":"code","source":"# listing recommended columns\ncol = X_train.columns[rfe.support_]\ncol","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### listing ignored columns","metadata":{}},{"cell_type":"code","source":"# listing ignored columns\nX_train.columns[~rfe.support_]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col2 = ['yr', 'holiday', 'workingday', 'temp', 'hum', 'windspeed','season_summer', 'season_winter', 'mnth_aug', 'mnth_sept', 'mnth_oct','weekday_sat', 'weekday_sun', 'weathersit_moderate', 'weathersit_bad']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating X_test dataframe with RFE selected variables\nX_train_rfe = X_train[col2]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## using 'STATS MODEL' let us iteratively build models","metadata":{}},{"cell_type":"markdown","source":"Model 1","metadata":{}},{"cell_type":"code","source":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# util to calculate VIF given training df\ndef compute_VIF(train_df):\n    # Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n    vif = pd.DataFrame()\n    vif['Features'] = train_df.columns\n    vif['VIF'] = [variance_inflation_factor(train_df.values, i) for i in range(train_df.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    vif","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compute_VIF(X_train[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_rfe.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_OLS_model(y_train, X_train_rfe):\n\n    # Add a constant\n    X_train_lm = sm.add_constant(X_train_rfe)\n\n    # Create a first fitted model\n    lr = sm.OLS(y_train, X_train_lm).fit()\n    \n    return lr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr1 = fit_OLS_model(y_train,X_train_rfe)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr1.params()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print a summary of the linear regression model obtained\nprint(lr1.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}